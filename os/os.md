# 结构组成

计算机基本结构：运算器、控制器、存储器、输入设备、输出设备。

存储器就是内存；运算器、控制器、寄存器组成 `CPU`；输入输出设备是外界设备。存储器和输入输出设备通过控制总线与 `CPU` 交互。

存储数据的基本单位是字节，1字节是8位，内存地址从0到总字节数减1。

`CPU` 的控制器控制 `CPU` 是读写数据还是执行计算，计算机负责计算，寄存器存放计算时数据。寄存器分为：通用寄存器，存放要计算的数据；程序计数器，存储要执行的下条指令地址；指令寄存器，存放当前执行的指令。

总线分为：地址总线，指定 `CPU` 要操作的内存地址；数据总线，读写内存数据；控制总线，发送接收信号，如中断、设备复位，控制读写数据。

`CPU` 执行过程：读取程序计数器，控制器通过地址总线指定地址，通知内存准备数据，数据准备好后通过数据总线给 `CPU`，`CPU` 收到后放入指令寄存器。程序计数器自增，指向下一条指令。`CPU` 分析指令寄存器的指令，确定指令类型，计算指令交给运算器，存储指令交给控制器。

程序运行时，内存中数据和代码分开存放，存放数据的区域是数据段，存放代码的区域是正文段。

要让程序跑的更快：减少指令数；减少每条指令的平均时钟周期；减少时钟周期时间，取决于硬件。

寄存器存放 `CPU` 正在处理的数据，速度最快，存储数据量较少；三层 `Cache` 为 `CPU` 高速缓存，速度相比寄存器慢些，存储的数据多些，`L1` 缓存分成数据缓存和指令缓存，离 `CPU` 最近。

`CPU` 不会和每一种存储器直接交互，每种存储器只和相邻的存储器交互。如 `CPU Cache` 从内存加载数据，写回数据也只写回内存，不会把数据写到硬盘。

`CPU` 访问数据，先取寄存器，再取三层 `Cache`，最后取内存。`L3` 缓存是所有 `CPU` 共享的，其他缓存是每个 `CPU` 独有的。

`CPU` 写入数据的方法：写直达，数据已在 `Cache`，先更新到 `Cache` 再写回内存，没在 `Cache` 里直接更新到内存，总要写回内存，会增加写操作时间；写回，若数据已在 `Cache` 里，更新 `Cache` 里的数据，同时把 `Cache Block` 标记为脏的，表示数据和内存不一致，写数据发现 `Cache Block` 存放的是别的数据，若被标记脏，把当前 `Cache Block` 数据写回内存，再把当前要写的数据，从内存读一份，再把要写入的数据写入 `Cache Block` 标记为脏，若不为脏，把要写的数据从内存读入 `Cache Block` ，再把数据写入标记为脏。

缓存一致性问题，多个 `CPU` 的缓存不一致。做到缓存一致：写传播，某 `CPU` 的 `Cache` 更新，必须传播到其他 `CPU` 的 `Cache`；事务串行化，某 `CPU` 对数据的操作顺序，必须对其他 `CPU` 是顺序的，看到相同顺序的数据变化。

避免伪共享问题，避免线程独立使用的数据出现在同一个 `Cache Line`，用填充或对齐的方法。

# 中断处理

中断是系统响应硬件设备请求的一种机制，操作系统收到硬件的中断请求，会打断正在执行的进程，调用内核的中断处理程序响应请求。中断请求的是响应程序，要尽快完成避免影响进程调度。若当前中断处理未完成，其他中断请求无法响应，可能会丢失。

为解决中断处理过长和中断丢失，将中断分成两部分：上半部分为硬中断，会中断处理程序，直接处理硬件请求，负责耗时短的工作，快速执行；下半部分为软中断，由内核线程执行，负责上半部分未完成的工作，延迟执行，通常耗时较长。

操作系统的基本能力：进程调度，管理进程、线程，决定使用哪个 `CPU`；管理内存，决定内存分配回收；管理硬件设备，让进程和硬件设备通信；提供系统调用，即操作系统和用户程序间的接口。

# 内存管理

内存分为内核空间和用户空间，程序使用用户空间为用户态，使用内核空间为内核态。应用程序进入内核空间需要通过系统调用，会触发中断进入内核态，内核处理完，主动触发中断回到用户态。

操作系统将不同进程的虚拟地址和不同内存的物理地址映射起来，虚拟地址通过 `CPU` 中的内存管理单元映射成物理地址访问。

程序由不同分段组成：代码、数据、栈和堆。段表维护虚拟地址和物理地址的映射，找到段基地址加上偏移量就是物理地址。分段容易产生内存碎片和内存交换效率低的问题。分段根据实际需求分配，不会产生内部碎片，但每个段长度不固定，易产生外部碎片。解决外部碎片用内存交换，将占用的内存写到磁盘 `Swap` 空间，再读回内存重新分配位置。

分页将内存空间切成固定大小，称为页。虚拟地址和物理地址映射用页表维护。若程序不足一页大小，也只能分配一页，会产生内部碎片。若内存空间不够，会将运行中进程最近没被使用的内存页面换出到硬盘，需要时再换入到内存，因交换页面较小，效率提升。分页可不用一次将程序加载到物理内存，在需要使用时才加载。

分页的虚拟地址包括页号和页内偏移。页号为页表的索引，页表包含每页的基地址。

分页的问题，维护页表需要较大的空间，用多级页表解决。一级页表没有被用到的地址不会分配二级页表，利用了局部性原理。页表一定要覆盖虚拟地址。

`TLB`，存放最常访问页表项的 `Cache`，为页表缓存。

段页式存储，先将程序分成多个段，再将每个段划分为多个页。

每个进程有独立的虚拟内存，每个虚拟内存的内核地址，关联的是相同的物理地址，切换到内核态可很方便访问。

`malloc` 有两种方式分配内存：`brk` 系统调用从堆分配内存，`free` 后会缓存；`mmap` 系统调用在文件映射区分配内存，`free` 后会归还给操作系统。分配的是虚拟内存，若未被访问就不会映射到无力内存。

内存紧张时，操作系统会回收内存，可回收的内存：文件页，干净页直接释放，脏页先写磁盘再释放；匿名页，`Swap` 把不常访问的内存写到片，再次访问从磁盘读入。都是基于 `LRU` 算法回收，回收内存都会产生磁盘 `IO`。回收内存，后台回收会开启后台线程操作，直接回收会阻塞进程。若直接内存回收都无法提供足够的内存，会触发 `OOM`，对每个进程打分，杀死得分最高的进程，得分取决于已使用的物理内存页。

`LRU` 算法的问题：预读失效导致缓存命中率下降；缓存污染导致缓存命中率下降。`Linux` 读取文件会缓存在 `Page Cache`。`LRU` 用链表实现，头部放最近使用的，末尾放最久没被使用的，空间不够淘汰末尾的数据。当访问的页在内存，直接移到链表头部；访问的页不在内存，移到链表头部同时淘汰链表末尾的页。

`Page Cache` 有预读机制，根据空间局部性原理，会将目标页相邻的页一起读进来，相邻页被访问到的概率大，减少 `IO` 次数，提高吞吐量。但如果提前加载进来的页没被访问，则预读失效，很可能淘汰掉热点数据，降低缓存命中率。

改进方法：`Linux` 实现两个 `LRU` 链表，活跃 `LRU` 和非活跃 `LRU`，活跃链表存放最近被访问过的页，非活跃链表存放很少被访问的页，预读页加入到非活跃链表头部，真正被访问时才插入到活跃链表头部，若预读页一直未被访问，从非活跃链表移除，活跃链表中的页降级先加入到非活跃链表。

`MySQL` 在同一个 `LRU` 链表上划出两个区域，`young` 和 `old`，每个区域有各自的头尾节点，区域占比约63:37。预读页加入到 `old`，真正被访问时才插入到 `young`。若预读页一直未被访问，会从 `old` 移除，不会影响到 `young` 中的热点数据。

设计思路都是将数据分成冷热数据，分别使用 `LRU`。

划分区域可避免预读失效，但存在缓存污染问题。批量读取数据，被访问一次就加入到活跃链表，如果这批数据在之后很长时间都不被访问，真正的热点数据被淘汰，整个活跃链表会被污染。解决缓存污染，提高进入活跃链表的门槛，让热点数据不被轻易替换。`Linux` 第二次访问页时，才将页从非活跃链表加入活跃链表。`MySQL` 第二次访问页时，若和第一次的访问间隔在1s内，不升级；若访问间隔超过1s，将页从 `old` 区域升级到 `young`。通过提高进入活跃链表的门槛，避免缓存污染的影响。

时间局部性，某条指令被执行，不久后可能再次被执行，某块数据被访问，不久后可能再次被访问。空间局部性，一旦访问某个存储单元，不久后附近的存储单元也会被访问。局部性原理表示，对内存的访问不会一下子访问全部类型，会更倾向于访问最近访问过的和热点数据附近的。局部性原理是实现虚拟内存的关键。

# 进程管理

进程至少有三种基本状态：运行，进程占用 `CPU`；就绪，可运行，等待 `CPU`；阻塞，进程等待某事件停止运行。

有大量阻塞进程会占用物理内存，通常把阻塞进程的物理内存空间换出到磁盘，进程没有占用物理内存的状态为挂起。进程挂起的情况：物理内存不足；`sleep` 让进程挂起。

`PCB`，进程控制块，进程的唯一标识，包括进程描述信息、资源分配、`CPU` 相关信息。`PCB` 通过链表组织在一起，相同状态的进程组成一个队列，根据进程状态分为阻塞队列、就绪队列。

创建进程，允许一个进程创建另一个进程，子进程继承父进程的资源，子进程终止，继承的资源还给父进程，父进程终止，子进程变成孤儿进程。阻塞进程，调用阻塞语句阻塞等待，只能由另一个进程唤醒。

进程上下文切换，保存好当前进程的 `CPU` 寄存器和程序计数器，切换到另一个进程。根据任务不同，可分成进程上下文切换、线程上下文切换和中断上下文切换。因进程是内核管理的，进程切换只发生在内核态。