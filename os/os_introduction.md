# 操作系统简介

程序运行做的事情：执行指令。处理器从内存取一条指令，解码后执行，完成后再继续执行下一条指令，直到程序完成。

操作系统实际做了什么：取得CPU、内存或磁盘等物理资源，对其进行虚拟化；处理并发；持久存储文件。

目标一：最小化操作系统的开销。目标二：应用程序间及OS和应用程序间提供保护，实现进程间彼此隔离。

# 虚拟化

为了让系统更易于使用，操作系统主要利用虚拟化技术。将物理资源转换为更通用、更强大且更易于使用的虚拟形式。

## 虚拟化CPU

虚拟化CPU，基本思想：运行一个进程一段时间，再运行另一个进程。通过时分共享CPU实现虚拟化。需要以高性能虚拟化CPU，同时保持对系统的控制。

### 受限直接执行

为高效执行，直接在CPU上运行程序，又需要对进程加一些限制，避免进程完全控制系统。用户模式下，运行的代码会受限，不能发出IO请求；内核模式下，运行的代码可以发出IO请求和执行受限指令。

执行系统调用，程序需执行 `trap` 指令，该指令会跳入内核将特权提升到内核模式，调用完成后，操作系统调用从 `trap` 返回指令，回到用户模式。执行 `trap` 时，要确保存储足够的调用者寄存器，能正确返回。

如果应用程序执行了非法操作，会将控制转移给操作系统。操作系统通过时钟中断重获CPU的控制器，避免程序恶意占用CPU。

上下文切换，为当前进程保存一些寄存器的值，为即将执行的进程恢复一些寄存器的值。

### 进程

进程是操作系统为正在运行的程序提供的抽象。进程的机器状态组成：

- 内存：指令存在内存中，正在运行的程序读取和写入的数据也在内存中；
- 寄存器：程序计数器、栈指针、帧指针。

运行程序需要将代码加载进内存中，现代操作系统惰性执行该过程，仅在程序执行期间需要加载代码片段时，才会加载。进程的状态：

- 运行：进程正在处理器上运行；
- 就绪：进程已准备好运行，但由于某种原因，操作系统不在此时运行；
- 阻塞：一个进程执行了某种操作，直到发生其他事件时才会运行。如进程向磁盘发起IO请求时会被阻塞。

常用的进程 `API`：

- `fork()`：会创建一个子进程，和父进程几乎一样。子进程不会从 `main()` 开始执行，而是从 `fork()` 返回。子进程返回值是0，父进程的返回值是子进程的 `PID`。
- `wait()`：延迟进程的执行，控制子进程执行完毕才返回父进程。
- `exec()`：从可执行程序中加载代码和静态数据，覆写代码段，初始化堆栈。没有创建新进程，而是将当前运行的程序替换成不同的程序。
- `pipe()`：一个进程的输出被链接到一个内核管道上，另一个进程的输入被链接到同一个管道上。
- `kill()`：向进程发送信号，包括要求进程睡眠、终止等。

进程调度指标：

- 周转时间：任务完成时间减去任务到达系统的时间。
- 响应时间：任务首次运行时间减去任务到达系统时间。

调度算法：

- `FIFO`：先来先服务。优点，简单易实现。如果有长任务，平均周转时间会降低。
- `SJF`：先运行最短任务，然后是次短任务。如果长任务先达到，平均周转时间会降低。
- `STCF`：最短完成时间有优先，向 `SJF` 添加抢占，每当有新工作进入系统，确定剩余工作和新工作中，谁的剩余时间最少，选择调度工作。平均周转时间减少，但响应时间和交互性差。
- `Round-Robin`：轮转，在一个时间片内运行一个工作，然后切换到运行队列的下一个任务。时间片长度必须是时钟中断周期的倍数。时间片越短响应时间表现越好，但上下文切换的成本也会影响性能。周转时间表现差。
- `MLFQ`：多级反馈队列，用历史经验预测未来。有许多独立的队列，每个队列有不同的优先级。一个工作只能存在于一个队列中，总是先执行较高队列中的工作。每个队列有多个工作，具有相同优先级，这些工作才有轮转调度。根据观察到的每个工作的行为调整优先级，如果一个工作长时间占用CPU，会降低优先级，在进程运行中学习其行为，预测未来行为。规则：
  - 规则1：若A的优先级>B，运行A；
  - 规则2：若A的优先级=B，轮转运行A和B；
  - 规则3：工作进入系统时，放在最高优先级；
  - 规则4a：工作用完整个时间片后，降低优先级；
  - 规则4b：若工作在其时间片内主动释放CPU，优先级不变；
  - 规则4：优化CPU计时方式，记录一个进程在某一层中消耗的总时间，而不是调度时重新计时。工作用完某一层的时间配额，无论中间主动放弃多少次CPU，就降低其优先级；
  - 规则5：为避免饥饿问题，经过一段时间S，将所有工作重新加入到最高优先级队列。
- 比例份额调度：利用了随机，按照每个工作的权重，确保每个工作获得一定比例的CPU时间，主要应用于虚拟机。
- 多处理器调度：CPU更新了内存的数据先写到缓存，随后再更新到内存，多CPU会存在缓存一致性问题，硬件会通过总线窥探，让每个缓存监听链接所有缓存和内存的总线，来发现内存访问。多CPU访问临界区，需要借助锁。还有一个问题是缓存亲和度，会尽可能将进程保持在同一个CPU上运行。
  - 单队列调度：把所有工作放入一个单独的队列，需要加锁保证原子性，每个CPU从队列中取出工作执行，对缓存亲和性支持较差。
  - 多队列调度：每个CPU处理一个队列的工作，容易产生负载不均，解决方法是迁移工作。




## 虚拟化内存

每个进程访问自己的私有虚拟地址空间，操作系统以某种方式映射到机器的物理内存上。一个进程的地址空间包含运行的程序的所有内存状态，包括代码、栈和堆。虚拟化内存的三个目标：

- 透明：程序不应该感知到内存虚拟化，好像拥有自己的私有物理内存，操作系统让不同的工作复用内存；
- 效率：高效实现虚拟化，包括时间和空间；
- 保护：进程只能访问自己的内存空间，不受其他进程影响；
- 灵活：程序能以任何方式访问自己的地址空间，让系统更容易编程；

内存主要分类：

- 栈：申请和释放由编译器隐式管理，又称自动内存，只存函数调用的信息。
- 堆：申请释放操作显式完成。

内存API：

- `malloc`：传入要申请的堆内存大小，返回指向新空间的指针。
- `free`：释放堆内存。
- `mmap`：在程序中创建一个匿名内存区域，该区域不与任何特定文件关联，而是与交换空间关联。

### 地址转换

地址转换可看成是受限直接执行方式的补充。硬件对每次内存访问进行处理，将指令中的虚拟地址转换为数据实际存储的物理地址。操作系统管理内存，记录被占用和空闲的内存位置，保持对内存使用的控制。

#### 动态重定位

动态重定位：每个CPU需要两个硬件寄存器，基址寄存器和界限寄存器。进程中使用的内存引用是虚拟地址，硬件将虚拟地址加上基址寄存器的内容，得到物理地址，发给内存系统。界限寄存器确保地址在进程地址空间范围内，提供了访问保护。

缺点，效率低、浪费空间、容易产生内部碎片。栈和堆之间会有空闲空间。

操作系统需要记录哪些空闲内存没有使用，以便能够为进程分配内存。最简单的数据结构是空闲列表，记录当前没有使用的物理内存的范围。为支持动态重定位，操作系统采取的行动：

- 进程创建时，操作系统为进程的地址空间找到内存空间，将数据结构标记为已用；
- 进程终止时，操作系统回收内存，将内存放回到空闲列表；
- 上下文切换时，因每个CPU只有一个基址寄存器和一个界限寄存器，对每个运行的程序值都不同。切换进程时，操作系统要保存和恢复寄存器，如保存在 `PCB`。
- 必须提供异常处理程序，操作系统启动时加载这些程序，当有进程非法访问内存，触发CPU异常，终止错误进程。
- 地址的转换过程完全由硬件处理，没有操作系统接入。

#### 分段

分段将进程的地址空间分成不同长度的段，一个段是地址空间里的一个连续定长区域，给每个段分配一对寄存器。分段机制使操作系统将不同的段放入不同的物理内存区域，避免虚拟地址空间中未使用的部分占用物理内存。如果访问非法的地址，会陷入操作系统，终止进程。

硬件用段寄存器做地址转换：

- 显式：用虚拟地址的开头几位标识不同的段，剩余部分存储偏移量。
- 隐式：硬件通过地址产生的方式确定段，程序计数器产生在代码段；基于栈或基址指针在栈段；其他在堆段。

为节省内存，可在地址空间之间共享内存段。为支持共享，需要为每个段增加保护位，标识程序能否读写该段，或执行代码。增加了保护位，引用内存除了检查虚拟地址是否越界，还要检查是否允许访问。

为支持将地址空间划分为大量较小的段，需要在内存中保存段表。

#### 分页

分页不是将一个进程的地址空间分割成几个不同长度的逻辑段（代码、堆、栈），而是分割成固定大小的单元，每个单元称为一页。物理内存看成是定长槽块的阵列，叫作页帧，每个页帧包含一个虚拟内存页。

分页最大的优点是灵活性，不管进程如何使用地址空间，栈和堆的增长方向如何。

为记录地址空间的每个虚拟页在物理内存中的位置，会为每个进程保存一个页表，为地址空间的每个虚拟页面保存地址转换。转换虚拟地址需要虚拟页面号和页内偏移量。每个进程的页表存储在内存中。

最简单的页表形式为线性页表，是一个数组。通过虚拟页号检索数组，找到物理帧号。每个页表项的内容包含许多不同的位：

- 有效位：指示特定地址转换是否有效，所有未使用的空间被标记为无效，如果访问这种内存，会终止进程。标为无效的页面不用分配物理帧，可节省大量内存。
- 保护位：表明页是否可读、写或执行。
- 存在位：表示该页是在物理存储器还是在磁盘上。
- 脏位：表示页面在内存中是否被修改过。
- 参考位：用于追踪页是否被访问，确定哪些页的访问频率高。

对每个内存引用，分页需要执行一个额外的内存引用，先从页表获取地址转换，开销很大。

`TLB`，地址转换旁路缓冲存储器，用于缓存虚拟地址到物理地址到转换。每次内存访问，硬件先检查 `TLB`，如果有期望的转换映射，不用访问页表；如果没有，访问页表寻找转换，将转换更新到 `TLB`。`TLB` 的成功依赖于空间和时间局部性：

- 时间局部性：最近访问过的项可能很快会再次访问；
- 空间局部性：程序会访问空间邻近的地址。

当 `TLB` 未命中，有两种处理方式：

- 硬件：硬件通过页表基址寄存器得知页表的位置，遍历页表找到正确项，取出转换映射，更新 `TLB`，再重试该指令。
- 软件：`TLB` 未命中，硬件抛出异常，进入内核模式，由操作系统更新 `TLB` ，再进入用户模式重试该指令。

### 空闲空间管理

空闲列表包含一组元素，记录堆中哪些空间还没有分配。如果请求内存大于连续空间大小，失败；如果请求内存小于连续空间大小，会找到一块可用的空闲空间，将其分割返回，更新空闲列表。当有内存被释放，如果临近的空间空闲，会将它们合并成一个大的空闲内存块。

分配内存时会在 `header` 中保存额外的信息，在返回的内存块之前，包含分配空间的大小，幻数（标记内存类型做完整性检查）。实际释放内存的大小是分配的空间大小加上头块大小。

基本分配策略：

- 最优匹配：遍历空闲列表，找到和请求大小一样或更大的空闲块，返回最小的一块。避免空间浪费，但遍历代价高。
- 最差匹配：找最大的空闲块，分割满足请求，将剩余块加入空闲列表。容易产生过量碎片，开销大。
- 首次匹配：找到第一个足够大的块返回。有速度优势，但容易让空闲列表开头部分有很多小块。一种优化方式是保持空闲块按内存地址有序，使合并更容易，减少内存碎片。
- 下次匹配：多维护一个指针，指向上次查找结束的位置，加速对空闲空间的查找。
- 分离空闲列表：若某应用程序经常申请一种大小的内存空间，就用一个独立的列表。若空闲空间耗尽，再向通用的空闲列表请求。
- 伙伴系统：当有内存请求，递归地将空闲空间一分为二，直到满足请求大小。只允许分配2的整数次幂大小，会有内部碎片。优点是空间释放后很容易合并。

`TLB` 只对当前进程有效，如果发生了进程切换，简单的方式是清空 `TLB`，这样开销比较大。通常在 `TLB` 加个地址空间标识符，`ASID`，可看作 `PID`，比 `PID` 少一位。这样`TLB` 可同时缓存不同进程的地址空间映射，用 `ASID` 区分是哪个进程。

`TLB` 的替换策略：

- `LRU`：最近最少使用，利用内存引用流的局部性，嘉定最近没有用过的项是好的换出候选项。
- `random`：随机选择一项换出去。

页表太大占用过多内存，增加负担。解决方法：

- 增加页大小：缺点是大内存页会导致每页内存的浪费，产生内部碎片。
- 混合方法：结合分段和分页，为每个逻辑分段提供一个页表，对于代码、堆和栈，会有三个页表。基址寄存器保存该段页表的物理地址，界限寄存器指示页表的结尾。确定地址引用哪个段，用地址空间的前两位。缺点还是使用了分段，容易产生外部碎片。
- 多级页表：页表很多项可能是无效的，如何在内存中只保留有效区域？将页表分成页大小的单元，如果整页无效，就不分配该页的页表。页目录存储页表的页位置，及页的有效性。不需要找到连续的空闲物理内存。缺点是，如果 `TLB` 未命中，需要从内存加载两次，才能获取地址转换。如果页目录过大，查找页目录需要较长的时间，可以将页目录拆为多层。
- 反向页表：保留一个页表，一个项代表一个物理页，会记录哪个进程在使用次页，及进程的哪个虚拟页映射到此物理页。搜索该线性表代价比较大，通常会建立哈希表。

### 交换空间

从磁盘取一定区域，将物理内存页放进去，需要的时候交换回去。需要在页表项里增加一个存在位，表示该页是否在物理内存上。访问不在物理内存中的页，会触发页错误。页表的某些位存储硬盘地址，操作系统接收到页错误，从硬盘将页读到内存中，更新存在位。

如果内存满了，需要交换出一些页。操作系统会预留一小部分空间内存，设置高水位线和低水位线，决定何时从内存清除页。物理内存少于低水位线个页可用时，会有交换守护线程释放内存，直到有高水位线个可用的页。

性能优化：把多个要写入的页聚合或分组，同时写入交换空间，提高磁盘效率。交换页时线检查是否有空闲页，如果没有通知交换线程释放，执行完毕唤醒原来的线程，将需要的页交换进内存。

物理内存包含所有页的子集，可看作虚拟内存页的缓存。缓存选择替换策略的目标是让缓存未命中率最少，用平均内存访问时间衡量：

- 最优替换策略：替换内存中在最远将来才会被访问到的页；
- `FIFO` 替换策略：页进入系统时，放入一个队列。发生替换时，从队尾踢出。优点是实现简单，命中率较低；
- 随机替换策略：内存满时随机选择一个页替换。
- `LRU`：替换最近最少使用的页



# 并发

线程类似于独立的进程，只有一点区别：共享地址空间，能访问相同的数据。进程切换把状态保存到进程控制块，线程切换把状态保存到线程控制块，只有一点区别：地址空间不变，不需要切换当前使用的页表。

临界区，访问共享变量的代码片段。如果一个线程在临界区执行，其他线程应被阻止进入临界区。

并发的非死锁缺陷，原子性缺陷用锁解决，顺序缺陷用条件变量解决。

死锁缺陷，破坏其中一个死锁条件即可解决：

- 互斥：线程对资源进行互斥访问；用比较并交换代替锁。
- 持有并等待：线程持有资源，同时等待其他资源。可通过原子抢占到所有锁避免。
- 非抢占：线程获得的资源不能被抢占；
- 循环等待：线程等待资源形成环路。获取锁时安排顺序即可避免。

活锁，同时让锁，一直抢锁失败，解决：随机等待时间再重复操作，降低线程间的重复互相干扰。

## 锁

锁是一个变量，需要声明类型。锁变量保存了锁在某一时刻的状态，是否被占用。还可以保存持有锁的线程，请求获取锁的线程队列，这些对锁的调用者不可见。

锁需要完成的目标：

- 互斥：能否阻止多个线程进入临界区；
- 公平性：当锁可用，是否每个竞争线程有公平机会抢到锁；是否会出现饥饿；
- 性能：使用锁之后的时间开销。

锁的实现方式：

- 关闭中断：进入临界区前关闭中断，保证原子执行。缺点很多，需要给进程特权，不支持多处理器，容易丢失中断；
- 硬件实现：设置指令实现互斥，用变量标记临界区是否被使用。等待锁的时候使用自旋，会浪费较多的时间片。解决方法是线程开始自旋时主动放弃CPU，变为 `ready` 状态，让其他线程运行，但如果竞争锁的线程过多，上下文切换的成本会很高。另一种方法是线程等待锁，加入到队列，用休眠代替自旋，队列决定下一个获得锁的线程，避免饿死。`Linux` 使用的是两阶段锁，第一阶段自旋等待，如果超过自旋次数仍然没有获得锁，进入第二阶段休眠。

## 条件变量

条件变量，是一个显式队列，当某些执行条件不满足时，线程把自己加入队列，等待该条件。当有其他线程改变上述状态，可以唤醒一个或多个等待线程，让它们继续执行。有两种操作：

- `wait`：释放锁，原子地让调用线程睡眠，线程被唤醒时，需要重新获取锁。
- `signal`：唤醒睡眠线程，调用时应该持有锁。

条件变量唤醒线程，暗示状态发生变化，但不会保证在它运行前一直是期望的情况。

## 信号量

信号量是一个整数值对象，因为初始值能决定其行为，一定要初始化信号量。两种交互方式：

- `sem_wait`：调用需要信号量的值大于1，减少信号量的值，若小于0，调用线程会挂起。
- `sem_post`：增加信号量的值，如果有等待线程，则唤醒一个。

信号量的值为负数时，这个值就是等待的线程个数。用于锁，信号量初始值设为1；用于条件变量，信号量初始值设为0。

## 基于事件的并发

等待事件发生，检查事件类型，做相应工作。调度就是决定接下来处理哪个事件，对调度显式控制，问题在于如何决定哪个事件发生。支持的API：

- `select()`：检查IO描述符集合是否准备好读取或写入，是否有异常情况要处理，返回集合中就绪的描述符个数。提供了一种构建非阻塞事件循环的方法，可简单检查传入数据包，从带有消息的套接字读取数据，根据需要回复。

如果接收到的事件发出阻塞调用，会造成巨大的资源浪费。为解决此限制，用异步IO，可以在IO完成前立即将控制权返回给调用者，应用程序可通过其他接口确定IO是否完成。或者使用中断，IO完成后由硬件通知应用程序。

# 持久性

磁盘不会被虚拟化。操作系统写入磁盘，首先确定数据要驻留在磁盘上的哪个位置，在文件系统维护的各种结构中对其记录。需要向底层存储设备发出IO请求，以读取现有结构或更新它们。为了提高性能，文件系统会延迟写操作一段时间，将其批量分组为较大的组。为处理写入期间系统崩溃，大多数文件系统都包含复杂的写入协议，如日志或写时复制，确保写入序列期间发生故障后可恢复到合理的状态。

CPU通过内存总线连接到系统内存。高性能IO设备通过常规IO总线连接到系统。外设通过外围总线连接到系统。才用分层架构，高性能设备离CPU更近，低性能设备离CPU远一些。

一个设备接口包含3个寄存器：状态寄存器，读取并查看设备当前状态；命令寄存器，通知设备执行某个具体任务；数据寄存器，将数据传给设备或从设备接收数据。

操作系统与设备的交互协议：操作系统反复读取状态寄存器，等待设备进入可接收命令的就绪状态；下发数据到数据寄存器；将命令写入命令寄存器，设备收到开始执行命令；轮询设备，等待命令完成。缺点是轮询太多，解决方法是CPU向设备发出请求，对应进程睡眠，当设备完成操作抛出硬件中断，引发CPU执行中断程序唤醒等待IO线程。但对于处理请求很快的设备，中断反而会使系统变慢，用轮训更好。因此通常考虑用轮询和中断混合，先尝试轮询，再考虑中断。

CPU和设备间传输数据时，会浪费很多时间。DMA是一种特殊设备，可以协调完成内存和设备间的数据传递，不需要CPU介入。

操作系统访问设备，第一种方式是用明确的IO指令；第二种方式是用内存映射IO，将设备寄存器作为内存地址提供，访问该地址。操作系统有设备驱动程序，用来和设备交互。

## 磁盘

磁盘驱动器由大量扇区组成，每个扇区可读写。更新磁盘时，驱动器保证单个扇区的写入是原子的。

磁盘通过引入磁性变化来永久存储数据，有多个盘片，每个盘片有两面，涂有磁性层，即使驱动器断电，也能持久存储数据。所有盘片围绕主轴连接在一起，主轴连接到一个电机，以恒定速度旋转。驱动器的每个表面有磁头，连接到磁盘臂上，磁盘臂移动将磁头定位在期望位置，数据读写由磁头完成。磁盘驱动器还有一小部分磁道缓存，是少量的内存，可快速响应对同一磁道的请求。

IO时间计算：

```
Tio = T寻道 + T旋转 + T传输
```

比较磁盘性能通常用IO速率：

```
Rio = 传输大小 / Tio
```

随机和顺序工作负载之间的性能差距很大。

磁盘调度可估计需要的时间，操作系统选择先执行话花费时间最少的请求。

`RAID`，廉价冗余磁盘阵列，由多个磁盘、内存及处理器来管理系统，通过某种形式的冗余，容许损失一个磁盘保持运行。

## 文件和目录

文件是一个线性字节数组，每个字节都可以读取或写入，每个文件都有一个与其关联的 `inode` 号。目录也有一个 `inode` 号，内容很具体，包含一个（用户可读名字，`inode` 号）对的列表。目录层次结构从根目录开始，使用某种分隔符来命名后续子目录。目录和文件可以有相同的名字，只要位于文件系统树的不同位置。

文件系统的接口：

- 创建文件：调用 `open()` 并传入 `O_CREAT` 标志。`open()` 可接受不同的标志，控制文件的操作权限。`open()` 的返回值是文件描述符，是一个整数，是每个进程私有的。创建文件的步骤，先创建 `inode`，跟踪所有文件的信息，再将可读的名称链接道该文件，将链接放入目录。
- 顺序读写文件：每个运行的进程打开3个文件，标准输入，标准输出和标准错误，所以再次打开文件，文件描述符从3开始。`read()` 调用重复读取文件中的一些字节，第一个参数是文件描述符，确定读取的文件，读取完毕返回0，调用 `close()` 关闭文件。
- 随机读写文件：`lseek()`，从文件的随机偏移量读取数据。
- 立即写入：`write()` 只是告诉文件系统，将来某个时刻将数据写入持久存储。为了性能，文件系统会将数据写入内存中缓存一段时间，之后写入存储设备。调用 `fsync()`，会强制将所有脏数据写入磁盘。
- 文件重命名：调用 `rename()`，是原子操作。
- 获取文件信息：查看文件元数据，用 `stat()` 或 `fstat()`。
- 删除文件：调用 `unlink()`，检查 `inode` 号的引用计数，删除可读的名称和 `inode` 号间的链接，减少引用计数，当引用计数为0时，释放 `inode` 和相关数据块，真正删除文件。
- 创建目录：`mkdir()`，空目录有两个条目，一个引用自身，一个引用其父目录。

文件的链接：

- 硬链接：调用 `linke()`，在目录中创建另一个名称，指向源文件的相同 `inode` 号。不能创建目录的硬链接，不能硬链接道其他磁盘分区中的文件。
- 软链接：是一个不同类型的文件，删除原始文件会导致软链接指向不再存在的路径。

挂在文件系统，用 `mount`，以现有目录作为目标挂载点，将新的文件系统粘贴到目录树的这个点上。

## 文件系统

构建文件系统，要考虑的点：数据结构，如何在磁盘上组织数据和元数据；访问方法，如何将进程发出的调用映射到数据结构上。

文件系统会将磁盘分成块，存放用户数据的磁盘区域为数据区域，`inode` 表用来存放文件的元数据，位图记录区域使用情况，超级块记录整个文件系统的情况。挂载文件系统，操作系统先读取超级块，初始化参数，将卷添加到文件系统树。

`inode` 结构，存储文件的元数据信息，并创建多级索引指向数据块。

读取写入文件会导致磁盘的许多IO，有巨大性能问题，使用系统内存 `DRAM` 可缓存重要的块。

解决崩溃一致性问题：

- `fsck`：查找文件不一致并修复；
- 预写日志：更新磁盘时，先将事务写入日志，提交事务，加上检查点更新元数据和数据。为保证能重复使用，日志通常被设计成循环数据结构。
