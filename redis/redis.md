# 哈希环

分布式缓存，要把数据水平切分到不同节点，某个 `key` 到哪个节点查，应该是确定的。用哈希

```mat
hash(key) % n
```

但如果节点数量变化，哈希值会变化，需要重新计算哈希迁移数据，迁移的数据量相对较大，成本高。

一致性哈希：对存储节点做哈希计算，如根据 `IP` 做哈希；当要存储访问 `key` 时，对 `key` 做哈希。将存储节点环上，环的范围是2^32。访问 `key` 时计算哈希，找到在环上的位置，顺时针遇到的第一个存储节点就是存放该 `key` 的节点。若节点数变化，能减少要迁移的数据，但不能保证节点分布均匀。

解决一致性哈希的分布不均问题，可加入虚拟节点，对一个真实节点做多个副本。不再将真实节点映射到哈希环，而是将虚拟节点映射到哈希环，再将虚拟节点映射到真实节点。

# 线程模型

单线程：接收处理请求由一个线程完成。其他后台线程：处理关闭文件、`AOF` 刷盘，异步释放内存。`del` 在主线程处理，删除大的 `key` 用 `unlink` 异步删除。这些任务操作很耗时，所以用单独线程处理。每个任务有独立的队列，后台线程相当于一个消费者，生产者把任务丢到任务队列，消费者轮询执行。

网络 `IO` 和事件处理是单线程，初始化完成等待事件，根据事件类型分别调用相应的函数：连接事件、读事件、写事件。

用单线程仍然很快的原因：大部分操作在内存完成，瓶颈主要是内存或网络带宽。单线程避免线程竞争。`IO` 多路复用处理请求。

6.0以后的版本用多个 `IO` 线程处理网络请求，因为性能瓶颈有时会出现在网络 `IO` 处理上，但命令执行仍然用单线程。启动后，默认创建额外6个线程：`Redis-server`，主线程，执行命令。`bio_close_file`，异步处理关闭文件任务。`bio_aof_fsync`，`AOF` 异步处理刷盘任务。 `bio_lazy_free`，释放内存任务。`io_thd_n`，`IO` 线程，默认 `io-threads` 是4，会启动三个。

# 数据类型

`String` 用 `int` 和 `SDS` 实现。`SDS` 相比于 `C` 字符串，既可保存文本数据，还可以保存二进制数据，用 `len` 属性判断字符串是否结束。拼接字符串前先检查空间大小，不足会自动扩容，不会造成缓冲区溢出。

字符串内部编码：保存的是整数值，可用 `long` 表示，将整数值保存到 `ptr` 属性，编码设置为 `int`。保存的是字符串，长度小于等于32字节，用 `SDS` 保存，编码设置为 `embstr`，长度大于32字节，用 `SDS` 保存，编码设置为 `raw`，不同是 `embstr` 用一块内存保存 `SDS` 和对象，`raw` 用两块内存分别保存对象和 `SDS`。`embstr` 实质是只读的，修改需要先转换为 `raw`。

`String` 的应用场景：缓存对象，直接缓存整个对象 `JSON`；将 `key` 分离为属性，用 `MSET` 存储，`MGET` 获取。常规计数，因 `Redis` 处理命令是单线程，执行过程是原子的，很适合计数，如计算访问次数、点赞、转发。分布式锁，用 `SET` 命令的 `NX` 参数实现，键不存在显示插入成功表示加锁成功，键存在显示插入失败表示加锁失败，还可设置过期时间，解锁要判断是加锁客户端，保证原子性。

`List`，底层用双向链表实现，可实现消费队列。`BRPOP` 阻塞式读取，客户端没读到队列数据自动阻塞，有新数据写入再开始读。

`Hash`，`value` 的形式是键值对，很适合存储对象，底层用哈希表实现。存储对象一半对象用 `String` + `Json` 存储，频繁变化的属性可抽出来用 `Hash` 存储。

`Set`，无序唯一的键值集合，存储顺序不按插入的先后顺序。`List` 可存重复元素，有序存储，`Set` 只能存非重复元素，无序存储。元素都是整数且个数小于512，用整数集合，否则用哈希表作为底层数据结构。`Set` 的差集、并集和交集计算复杂度较高，数据量大时容易阻塞，为避免主库阻塞，可选择从库执行。场景：点赞数、共同关注。

`Zset`，相比于 `Set` 多了个排序属性 `score`，每个元素有两个值组成，一个是有序集合的元素值，另一个是排序值。底层用跳表实现。场景：排行榜。用跳表实现原因：节点指针较少，范围查询实现简单，实现简单。

`BitMap`，位图，是一串连续的二进制数组，适合一些数据量大且用二值统计的场景。用 `String` 作为数据结构，保存为二进制的字节数组。

# 持久化

`AOF`，每执行一条写命令，追加到日志文件，重启时先读取命令再执行。先执行写操作，后记录日志，可避免额外的检查开销，不会阻塞当前写操作命令执行。风险：先执行写操作，此时宕机数据会丢失。写操作和写日志是同步的，可能影响下一个命令执行。

写回硬盘策略：`Always`，每次写入文件就执行 `fsync()`。`Everysec`，创建异步任务执行 `fsync()`。`NO`，操作系统控制。不同之处在于 `fsync()` 的调用时机。

`AOF` 重写机制，避免文件过大。重写时，读取所有键值对，用命令记录到新文件，替换掉老文件。重写失败会污染 `AOF` 文件，直接删除。重写过程由后台子进程执行，这样不会阻塞主进程，用子进程相比线程性能高，访问共享数据不用加锁。

主进程修改数据后，会触发写时复制，如果修改的键很大，复制物理内存数据比较耗时，可能阻塞主进程，还会导致主进程和子进程数据不一致。`AOF` 重写缓冲区解决数据不一致，执行完写命令，写到 `AOF` 缓冲区和 `AOF` 重写缓冲区，写完向主进程发送信号，主进程收到信号调用处理函数，把 `AOF` 重写缓冲区的内存追加到新的 `AOF` 文件，替换掉旧文件。

整个 `AOF` 重写只有发生写时复制，执行信号处理函数会对主进程造成影响。 

`RBD` 快照，记录某一瞬间的内存数据，回复效率更高，不需要执行命令。创建一个子进程定期生成 `RDB` 文件，避免阻塞主进程。每次执行快照，把内存数据都记录到磁盘，是比较重的操作。快照间隔太长有丢数据风险，太短影响性能。若所有内存被修改，此时内存占用会是之前的2倍，针对写操作多的场景要留意快照过程内存的变化。

混合持久化，`AOF` 重写日志时，子进程以 `RDB` 的方式写入 `AOF` 文件，主进程处理的操作记录到重写缓冲区，以 `AOF` 方式加入 `AOF` 文件，写完后通知主进程用含有 `RDB` 和 `AOF` 格式的文件替换旧文件。前半部分是 `RDB`，后半部分是 `AOF`，既保证加载快，又减少子进程的工作。

阻塞主进程：`fork()` 子进程创建页表；共享数据被修改，发生写时复制。

写入大 `key` 的影响：`Always` 策略阻塞时间会比较久。`AOP` 日志写入很大 `key`，日志很大很快触发 `AOP` 重写机制。`key` 增多页表会很大，`fork()` 创建子进程会耗时更多。如果 `fork()` 耗时超1秒，要减少单个实例的内存占用。集群模式会造成节点数据分布不均。最好在设计阶段，把大 `key` 拆分成小 `key`，不要使用 `DEL` 删除大 `key`。

对过期键的处理：`RDB` 生成阶段，对 `key` 检查，若过期不会写入，加载阶段，主载入时不会加载过期键，从载入时无论是否过期都要加载。`AOF` 写入，过期键未删除，保留此过期键，被删除后追加 `DEL`，重写阶段，过期键不会被保存到重写的 `AOF`。

# 内存管理

可对 `key` 设过期时间，可在某个时间戳之后删除，或在一定时间后删除。若 `key` 有过期时间，会带上过期时间把 `key` 存到一个过期字典。过期字典的 `key` 是个指向某个键对象的指针，`value` 保存过期时间，本质是哈希表。查一个 `key`，先检查是否在过期字典，若在，获取过期时间判断是否过期。

过期策略：定时过期，设置 `key` 过期时间后创建一个定时事件，时间到达后由事件处理器自动删除，可保证 `key` 尽快被删除，但会占用一定的 `CPU` 时间，影响响应速度。惰性删除，每次访问时检测 `key` 是否过期，过期则删除，对 `CPU` 友好但对内存不友好，不访问就一直占用内存。定期删除，每隔一段时间随机检查一部分 `key` ，删除过期的，对内存和 `CPU` 做了均衡。

`Redis` 选择惰性删除+定期删除。访问修改 `key` 时，检查是否过期，若过期则删除。每秒10次过期检查，随机抽20个删除过期 `key`，若过期超过5个，继续抽查，否则等待下一轮检查，循环的时间上限不能超过25ms。

内存淘汰策略，运行内存超过设置的最大值后，删除符合条件的 `key`。不淘汰数据策略：运行内存超过最大值，不淘汰数据，新数据进入报错。数据淘汰策略：随机淘汰设置了过期时间的任意键值，优先淘汰更早过期的键值，淘汰设置过期键值中最久未使用的，淘汰设置过期键值中最少使用的。

`Redis` 不用传统 `LRU`：用链表管理数据带来额外的空间开销，访问数据需要移动链表太耗时。用一种近似 `LRU` 节省内存，在对象结构体加额外字段记录最后一次访问时间，随机采样淘汰最久未使用的，但无法解决缓存污染，一次读取大量数据只被读取一次。

`Redis` 用 `LFU`最近最不常使用，解决缓存污染。根据数据访问次数淘汰数据，若数据过期被访问多次，那么未来被访问的频率也更高。记录每个数据的访问频次，会随时间推移衰减。每次被访问，会做衰减操作，和上次访问间隔越大衰减值越大，根据访问频次淘汰数据。

# 高可用

主从复制，保证多台服务器的数据一致性，采用读写分离。主服务器可进行读写操作，发生写操作后自动同步给从服务器，从服务器只读，接受主服务器同步来的写命令执行。

主从首次同步：建立连接，从收到响应会记录的 `runID`；主同步数据给从，生成 `RDB` 文件发送给从，从收到文件清空当前数据载入收到的文件，若期间有新的写操作，导致数据不一致，主生成 `RDB`、主发送 `RDB`、从加载 `RDB` 期间，写命令加入 `replication buffer`；从加载完 `RDB` 回复确认消息给主。

完成首次同步，主从间维护了一个 `TCP` 连接，后续主发写命令给从，保证主从一致。首次同步主开销大的过程：生成 `RDB`，传输 `RBD`。需要 `fork()` 多个子进程，容易阻塞主进程，`RDB` 太大会占网络带宽。缓解主的压力：从可以有自己的从，分摊到其他从。

若主从同步期间连接断开，主从数据不一致，再次进行全量同步开销太大。增量复制，只把网络断开期间的写命令同步给从。主将命令写给从，还会写到 `repl_backlog_buffer` 环形缓冲区，保存最近发送的命令。从重新连接主，把自己的复制偏移量发给从，主对比自己的偏移量和从的差距，如果从要读的数据在缓冲区，用增量同步，不在缓冲区，用全量同步。缓冲区的大小设置为：从重连需要的平均秒数 * 主平均产生的写命令大小。

主有 `key` 过期或被淘汰，发送给从 `DEL` 命令执行。

一个主只有一个 `repl backlog buffer`，只在增量复制中使用，满了会覆盖。`replication buffer`，每个连接的从都分配一个，增量和全量都有，满了会断开连接删除缓存。

应对主从数据不一致：监控主从节点复制进度，屏蔽进度差值较大的从节点给客户端。

减少主从切换数据丢失：异步复制丢失，主从延迟过大，主节点拒绝接受请求，客户端发现主不可用，先将数据写入本地缓存，恢复后再写入。集群脑裂丢失，主与从失联，客户端写入主一些数据，哨兵选出新的主，老的主回到集群降为从，清空数据重新同步，导致数据丢失。当主发现从下线数量太多或同步延迟大，禁止写操作。

主从架构，主挂了需要人工介入，还需要通知客户端。哨兵机制实现主从故障转移，监测主是否存活，若主挂了，选举一个从切换为主通知客户端。哨兵也是个节点，负责：监控、选主、通知。

主从架构，从库不会进行过期扫描，从库对过期的处理是被动的，等待主库删除过期键后同步 `del` 给所有从库。

哨兵每隔1秒给所有主从发送 `PING`，主从收到命令返回响应给哨兵。若主或从未在规定时间内响应，哨兵标记其为主观下线。为减少误判，会部署成哨兵集群，多个哨兵一起判断。哨兵判断主观下线后，向其他哨兵发命令，其他哨兵收到命令响应，若哨兵赞同数达到设定值，该主被标记为客观下线。

主从故障转移，需要在哨兵集群选一个 `leader` 执行。哪个哨兵判断客观下线，该哨兵就是候选者，向其他哨兵发送投票命令，候选者投自己，其他哨兵投给先发命令的候选者。选出一个从转换为主，优先选节点设置优先级高、接收复制数据多、节点ID较少的。哨兵向选出的从发送命令，变为新主，通知其他从新主，用发布订阅机制通知客户端。

客户端和哨兵建立连接，会订阅哨兵的频道，主从切换完成，哨兵向频道发布新主节点的消息。若有节点上线，哨兵发送命令成为从。

哨兵之间通过发布订阅机制互相发现，从主节点得知所有从节点信息。

一台服务器不够缓存数据，用集群方案，将数据分布到不同的服务器，降低对单主节点的依赖。集群用哈希槽处理数据和节点的映射关系，一个集群共有16384个哈希槽，类似数据分区。每个键值对，用 `CRC16` 算法计算 `key` 得到一个16bit的值，对16384取模得到哈希槽。

哈希槽映射节点：创建集群时平均分配到节点数。

`Redis` 集群要至少三个主节点，一个主节点搭配至少一个从。除主从复制，所有节点用 `Gossip` 协议通信，交换维护节点元数据信息。读请求给从，写请求给主，主同步数据给从。数据按 `slot` 分布在多个节点，节点间数据共享，可动态调整数据分布。

# 缓存

为避免访问数据库请求过多，用 `Redis` 做缓存层，会有以下问题。

缓存雪崩：为保证缓存与数据库数据一致，给 `Redis` 数据设置过期时间，缓存数据不存在需要访问数据库更新。大量缓存数据同时过期或 `Redis` 服务不可用，会有大量请求直接访问数据库，即缓存雪崩。解决大量数据同时过期：均匀设置过期时间。处理请求时若发现缓存未命中，加互斥锁保证只有一个请求构建缓存。业务线程不更新缓存，由后台线程更新，当内存紧张时淘汰数据，发现缓存失效后主动更新。解决 `Redis` 故障：启动服务熔断，暂停业务对缓存服务访问，启动请求限流，只将少部分请求发送到数据库处理。用集群模式实现高可用。

缓存击穿：某个热点数据过期，大量请求访问数据库。解决：互斥锁，同一时间只有一个线程更新缓存，其他线程等锁释放后重新读缓存。不给热点数据设置过期时间，或由后台线程异步监控更新。

缓存穿透：访问的数据既不在缓存，也不在数据库。原因：业务误操作，黑客攻击。解决：限制非法请求。在缓存设置默认值。用布隆过滤器快速判断数据是否存在，避免通过查数据库判断。

两个请求并发更新同一条数据，可能出现缓存和数据库数据不一致的现象。旁路缓存策略：写策略，更新数据库后删除对应的缓存。读策略：读缓存命中返回数据，未命中从数据库读取写入缓存。需要保证更新数据库+删除缓存是原子的，否则会造成数据不一致，若对缓存命中率要求很高，删除缓存对性能有影响。用更新数据库+更新缓存解决，更新缓存前加个分布式锁，保证只有一个请求更新，更新完缓存，加上较短的过期时间，保证最终一致性。用删除缓存而不是更新

动态缓存热点数据，只将一部分热点数据缓存起来，通过数据最新访问数据排名，过滤掉不常访问的数据，只留下经常访问的数据。做一个排序队列，根据访问时间更新队列，越是最近访问越靠前。定期过滤掉队列最后五分之一的数据，从数据库随机读取相同量的数据加入队列。

写回策略，更新数据只更新缓存，设置缓存数据为脏，立即返回。数据的更新通过批量异步操作。很适合写多的场景。数据不是强一致的，会有丢数据的风险。

# 补充

管道技术，将多个命令整合发送给服务器处理，统一返回给客户端，要避免发送的命令过大，是客户端提供的功能。

`Redis` 的事务没有提供回滚机制，不能保证原子性。不支持事务是因为和 `Redis` 追求简单高效不符合，`Redis` 事务的错误通常是编程错误造成的，很少出现在生产环境。将多个命令绑定在一起执行，期间不能被中断。如果有某个操作执行失败，不保证原子性。

分布式锁控制分布式环境下，某个资源同一时刻只能被一个应用使用。`Redis` 的 `Set` 命令 `NX` 参数可实现不存在才插入，不存在显示插入成功表示加锁成功，存在显示插入失败表示加锁失败。加锁包括读锁变量、检查锁变量和设置锁变量三步，需要以原子方式存在，加上选项 `NX` 实现加锁。锁变量要设置过期时间，避免客户端拿到锁后异常不能释放。锁变量需要区分不同客户端，每个客户端设置唯一值。

解锁的操作，判断锁变量是否为加锁客户端，是的话执行删除，两部操作也需要是原子的，用 `Lua` 脚本保证解锁原子性。

`Redis` 分布式锁优点：性能高、实现方便。缺点：超时时间不好设置。

解决集群环境下分布式锁的可靠性：`Redlock`。基于多个节点，客户端和多个独立节点申请加锁，半数以上完成加锁操作则成功。