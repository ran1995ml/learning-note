# Kafka

解耦生产者和消费者。

一条数据是一条消息，元数据 `key` 用于选择分区，`offset` 用于消费者定位。为提效，按批次写入。主题像一张表，对消息归类，可有若干分区，以追加写入，顺序读取。分区实现数据冗余和伸缩。生产者写入数据。多个消费者组成一个消费者组读取数据，每个分区只能被一个消费者使用。服务端称为 `broker`，接收数据写到磁盘。集群会选出 `broker` 作为集群控制器，监控其他 `broker`，分配分区。一个分区从属于一个 `broker`，称为分区的首领。一个分区可分给多个 `broker`，这时会复制分区。

消息保留策略，保留一段时间或消息达到一定大小。磁盘影响生产者，内存影响消费者。消费者读取的消息会直接在 `PageCache`。`JVM` 不用太多内存，大多数内存用做 `PageCache`。因为共享 `PageCache` 的缘故，需要单独部署，不要混部。网络决定了能处理的最大数据流。`CPU` 相对影响不大，若生产者发送的数据未压缩，但数据保存设置了压缩格式，会在 `broker` 压缩，压缩主要为了减少网络带宽占用，节省磁盘。

发送数据创建 `ProducerRecord` 对象，要包含目标主题和内容，还可指定键或分区，发送前先序列化传给分区器。未指定分区，按 `key` 指定。添加消息到一个 `batch`。独立线程将 `batch` 发到 `broker`。`broker` 写入成功返回一个元数据对象，包含主题和分区，否则返回错误。发送方式有同步和异步两种。`acks` 指定多少分区副本收到消息才算写成功。`buffer.memory`，生产者内存缓冲区，缓冲要发送到消息。

`Avro` 用二进制序列化，将 `schema` 保存到一个注册表。

键决定数据写到哪个分区，为 `null` 会用轮训均衡分布到各个分区。

消费者从属消费者组，一个组内的消费者订阅同一个主题，每个消费者接收一部分分区消息。再均衡，分区的所有权从一个消费者转移到另一个消费者，在这期间会造成整个群组一小段时间不可用。有个 `broker` 是群组协调器，消费者向它发送心跳，在轮询消息或提交偏移量时发送心跳。如果停止发送心跳，会话过期认为死亡，触发再均衡。

消费者加入群组，向群组协调器发请求，第一个被加入的消费者成为群主。群主从协调器获得群组的成员列表，负责分配分区，将分配结果返回给群组协调器，最终由群组协调器分发给各消费者。参数配置，拉取的一批数据大小，防止消费者消费不过来，减少 `broker` 的负载。和集群交互时，通过 `group.id` 计算哈希选 `broker` 作为群组协调器。

消费者向 `_consumer_offset` 发消息，包含每个分区的偏移量。关闭消费者或再均衡前最后一次提交，要确保提交成功，用同步提交，处理消息逻辑提交用异步提交。发生再均衡，要在即将失去分区所有权前提交偏移量。

用 `Zookeeper` 维护集群成员信息，每个 `broker` 有一个唯一标识符，启动后创建临时节点将标识符注册到 `Zookeeper`。订阅路径后有服务加入或推出，可获得通知。

分区、`broker` 、`ISR` 元数据存在 `zookeeper`，集群控制器感知到元数据变化，会通知其他 `broker`。

控制器除了具有一般 `broker` 的功能外，还负责分区首领选举。集群第一个启动的 `broker` 注册成为控制器。新的 `broker` 生成控制器后，会递增得到更大的 `epoch`，其他 `broker` 忽略旧的 `epoch` 信息。控制器通过 `Zookeeper` 路径得知 `broker` 存活，若分区失去首领，会遍历该分区的 `broker` 选出新首领，发请求给新首领和跟随者。新首领处理客户端请求，跟随者从新首领复制消息。通过 `epoch` 避免脑裂。

副本有首领和分区两种类型。为保证一致性，客户端请求经过首领副本。跟随者副本不处理请求，只从首领复制消息。复制数据发请求会带上偏移量，首领根据请求的偏移量管理各副本的复制进度。

每个分区有一个首选首领，是创建主题时选定的首领。为了让 `broker` 负载均衡，选首领时会先尝试让首选首领成为首领。

提供了基于 `TCP` 的二进制协议，按顺序处理请求。`broker` 在监听的端口上运行一个 `Accepter` 线程创建连接，`Processor` 线程放入请求队列，从响应队列获取响应结果。`IO` 线程处理请求队列的消息。

客户端只能发请求给首领副本。用元数据请求确定首领副本的位置，返回主题分区首领信息，可发送给任意 `broker`，每个 `broker` 都缓存了这些信息。客户端收到请求后会把这些信息缓存起来，根据配置定时请求元数据得知是否变更，若收到非首领错误会重新刷新元数据。

消息写入本地磁盘先写到缓存，不保证何时刷新到磁盘。不会一直等待数据被写磁盘，依赖复制保证消息持久性。

消费请求客户端可指定最多从一个分区返回多少数据，以满足消费者的处理能力。还可以设置下限，等有足够的数据再返回，减少网络开销。不会让客户端一直等待，设置超时时间即使没有积累足够的数据也会发送。用零拷贝发送数据，将数据从 `PageCache` 发到网卡，减少数据拷贝次数。只有被写入所有同步副本的消息才能读取，避免消费的数据不一致。

存储的基本单元是分区，一个分区只能放在一块盘，保证顺序写入。确保副本在 `broker` 间平均分配，不同副本分到不同 `broker`。随机选择 `broker` 以轮询方式分配。

文件目录可指定多块盘，每次分配分区选择分区数量最少的目录。为每个主题设置数据保留时长、保留大小。大文件查找删除很费时，分区会分段，默认一个段包含 `1GB` 或一周的数据，以较小的为准。正在写入数据的片段叫活跃片段，不会被删除。会为每个片段打开一个文件句柄。

消息和偏移量保存在文件，用零拷贝发送数据，避免对生产者压缩过的消息解压再压缩。消息还包含大小、校验和、压缩算法、时间戳等信息，时间戳可以是生产者发送配置或到达 `broker` 的时间。生产者发送消息压缩，会把同一批次的消息压缩在一起。

为快速定位偏移量，为每个分区维护一个索引，映射到片段文件和文件里的位置。索引也被分段，删除消息要删除响应的索引，不维护索引的校验和，损坏会重新生成。

`compact` 策略，用于压缩键值对数据。用多个清理线程，读每个分区的键值到 `map` ，每个键只保留最近一个消息。当发送一个键值且值为 `null` 的消息，称为墓碑消息，会将该键的所有消息删除。墓碑消息要保留较长一段时间，让消费者感知到。不会清理活跃片段。

`Kafka` 的可靠性保证：分区消息顺序。消息被写入所有同步副本，才是已提交。只要还有一个副本活跃，已提交消息不会丢失。消费者只读已提交消息。

同步副本的条件：近期向 `Zookeeper` 发送过心跳；近期从首领获取过最新消息。若副本在同步和非同步间快速切换，可能是垃圾回收导致的。使用 `zk`，元数据写到 `zk`。不使用 `zk`，元数据保存到元数据日志对应的主题。

若首领副本失效，其他副本都不同步，为保证可用性，可设置允许不同步副本称为首领。为保证一致性，需要等首领上线。还可设置达到一定的同步副本数，才可继续向该分区写数据。根据可靠性需求配置恰当的 `acks`。若生产者没收到响应重试，会造成消息重复。可在消息加上唯一标识符，消费者读取时处理。生产者幂等性，每个消息加上 `ProducerId` + 序列号，若发现重复，则不写入。

要保证轮询，避免消费者和 `broker` 失去心跳。可轮询获取数据后，提交给工作线程处理保持轮询。

每个 `Broker` 充当事务管理器，管理事务元数据，包括事务ID和状态，协调生产者和事务回滚。在 `__transaction_state` 主题中维护事务状态，用于故障恢复。消费者只能读取已提交事务。

`MirrorMaker` 用做集群间的数据复制。包含一组消费者从源集群消费数据，生产者向目标集群发送数据。
