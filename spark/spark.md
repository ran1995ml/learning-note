# Spark

`Driver` 协调应用执行。`SparkContext` 申请资源创建 `Executor`，创建 `RDD` 生成 `DAG`，`DAGScheduler` 划分 `DAG`，生成 `Stage`，代表可并行执行的一组任务，以 `TaskSet` 传给 `TaskScheduler`，分发任务到 `Executor` 的一个线程执行。`DAG` 分为逻辑执行图和物理执行图，逻辑执行图是 `RDD` 间的依赖。

`Executor` 分配任务：均衡分配、数据本地性优先、失败重试转移到另一个 `Executor`。

`RDD`，弹性分布式数据集，只读。分布式，有分区。弹性，可以放任意数据类型。惰性执行，有助于优化、容错恢复。

堆内存划分：`Storage` 内存，存储 `cache`、广播变量。`Execution` 内存，放 `shuffle`、`join`、`aggr` 过程的临时数据。预留内存，防止 `oom`。系统预留内存，存储 `Spark` 对象。`Other` 内存，存储转换 `RDD` 需要的数据，如依赖。

堆外内存划分：`Storage` 和 `Execution` 各分一半。

动态占用机制，设定各部分的空间范围，内存都不足时存到磁盘，有一方不足借用其他空间。可让对方让出空间，转移到磁盘。

`RDD` 是记录分区的只读集合，`RDD` 之间存在依赖关系，构成血缘。血缘保证每个 `RDD` 都可被重新恢复。

`HashShuffle`，每个任务每个分区输出一个文件，产生分区数 * 任务数个文件。合并机制优化，共用一个核的任务相同的分区写入一个文件，产生核数 * 分区数个文件。

`SortShuffle`，数据先写入数据结构，达到阈值后写入磁盘，清空数据结构，写磁盘前先排序。最后每个任务将所有临时文件合并，生成一个索引文件，标识各分区的偏移量。

`BypassSortShuffle`，运行条件任务数小于配置阈值，不能是聚合类的算子。小于200不进行排序，因为数据量本身少节省排序的开销。

`MR` 总要将 `Map` 端数据写磁盘，`Spark` 可配置内存不足时才写磁盘。`Reduce` 不用等 `Map` 全部完全则可开始拉数据。对中间数据有缓存管理，调整内存和磁盘使用比例，可动态平衡。

`Shuffle` 过程避免小文件，文件过多要维护过多的元数据，从多个数据读文件会有更多的磁盘IO。
