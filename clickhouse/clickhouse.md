# ClickHouse

`ROLAP`，用星型模型。`MOLAP`，预聚合加速。`HOLAP`，两者混合。

具备 `DBMS` 的基本功能：`DDL`、`DML`、权限控制。列式存储，默认用 `LZ4` 压缩算法。使用 `CPU` 指令向量化执行，单条指令操作多条数据，最大程度提高并行化性能，能用钱解决的都不是问题。表引擎设计，对存储引擎抽象。支持分区分片。采用多主架构，每个节点角色对等，客户端可访问任意一个节点。

数据分片，将数据横向切分，每个分片对应一个服务节点，分片数量上限取决于节点数量。提供本地表和分布式表，一张本地表相当于一个数据分片，分布式表不存数据，是本地表访问代理，用于访问多个数据分片。

`Column` 表示列数据，`Field` 表示单值。`DataType` 负责序列化反序列化。`Block` 封装 `Column` 和 `DataType`，简化使用。`IStorage` 指代数据表，有不同的表引擎实现，查询时根据 `AST` 返回数据交给 `Interpreter` 处理。`Parser` 创建 `AST`，`Interpreter` 解释 `AST` 返回相应的 `Block`。

函数分两类：普通函数和聚合函数。

集群由分片组成，每个分片由副本组成。分片是逻辑概念，物理承载是副本。

`clickhouse-local`，可独立运行大部分查询，不依赖于服务端，只能用 `File` 表引擎。

数据类型上，没有时间戳类型只有 `DateTime`。支持数组、元组、枚举、嵌套。`Nullable` 类似 `Optional`，表示基础类型可为 `Null`。

数据库实质是磁盘上的一个目录。表引擎决定数据如何被存储及加载。临时表生命周期和会话绑定，只支持 `Memory` 引擎，不属于任何数据库。数据分区，查询跳过不必要的目录，提升查询性能，只有 `MergeTree` 类引擎支持。物化视图有独立存储支持表引擎，源表写入数据同步更新。普通视图是查询代理不存数据。

`ALTER` 操作只有部分表引擎支持。`DETACH` 分区，物理数据没删除，转移到表目录的 `detached` 子目录。`ATTACH` 分区，将某个分区数据重新装载回去。移到 `detached` 子目录，表示脱离了管理，不会主动清理，需要主动删除。

`DELETE` 和 `UPDATE`，适用于批量数据修改和删除，不支持事务，无法回滚，异步后台执行。执行一次 `Mutation` 操作，会在系统表生成一条执行计划，可查询完成进度。删除过程旧目录被标记为非激活状态，以 `mitation_id` 结尾创建新目录，旧目录等到下次合并时触发删除。

数字字典，键值存储，持支持动态更新，适合存常量或维表。

`ReplacingMergeTree` 可删除重复数据。`SummingMergeTree` 会按排序键自动聚合。加上 `Replicated` 支持数据副本。`MergeTree` 支持主键索引、副本、分区、`ALTER`。数据以片段写入磁盘，不可修改。为避免片段过多，后台线程定期合并相同分区的片段。分区键只能是一级分区，可用单个列字段，也可为列表达式。排序键指定一个片段如何排序，默认主键和排序键相同。按照主键生成一级索引，加速表查询。`index_granularity`，索引粒度，默认8192，每隔8192行生成一条索引，新版本可配置自适应调整间隔。`Settings` 里还有多路径存储、`ttl` 配置。

数据表的物理结构：表目录有多个分区目录。分区目录下的文件，`checksums` 校验文件保存大小和哈希值快速校验完整性；`columns` 保存分区下的列字段信息；`count.txt` 记录分区下的总行数；`primary.idx`，一级索引文件，二进制存储，存放稀疏索引，只能在创建表时声明，查询时排除主键条件范围外的文件，减少数据扫描范围；`[Column].bin` 数据文件，`LZ4` 压缩表示一列数据；`[Column.mrk]` 列字段标记文件，保存 `.bin` 中数据的偏移量；`[Column].mrk2` 自适应大小的索引间隔；`partition.dat` 分区表达式最终值；`minmax` 记录分区下分区字段对应原始数据最大和最小值；二级索引，进一步减少扫描数据范围。

分区ID若既不属于整型，也不属于日期，取哈希值作为取值。元组方式定义分区用 `-` 依次拼接。

分区目录组成：分区ID + `MinBlockNum` + `MaxBlockNum` + `Level`。最大最小数据块编号，记录新区数。合并层级是某分区被合并的次数。分区目录在数据写入时才创建。每有一批数据写入，会生成一批新的分区目录，之后合并相同分区的目录，索引和数据文件都会合并。旧分区目录再之后删除。

一级索引用稀疏索引，每一行索引标记对应一段数据，可用少量索引标记能记录大量数据区间位置，索引占用空间小所以可常驻内存。数据以索引粒度分为多个小区间，一级索引和数据标记的间隔粒度相同，数据文件也按该粒度压缩。

查找索引时，过滤条件转换成区间。索引范围先分成8个，无交集的区间剪掉。接着递归再分成8个，合并交集的子区间返回结果。

二级索引，`index_granularity` 定义数据粒度，`granularity` 定义聚合汇总的粒度，即一行二级索引能跳过的 `index_granularity` 区间个数。在一级分区粒度划分的区间基础上，汇总每 `granularity` 个区间，支持 `minmax`、`set`、`ngrambf_v1`。

每个列独立存储，`.bin` 文件承载数据物理存储，只保留当前分区片段的数据。写入前先按排序键排序，再压缩。`.mrk` 为 `.bin` 和一级索引建立关联，和一级索引对齐。一级索引可常驻内存，`.mrk` 用 `LRU` 加速。读取某列数据，不用加载整个 `.bin` 文件，根据 `.mrk` 只加载特定压缩块。压缩块的大小限制在64KB~1MB间。

数据写入先生成分区目录，写入一批生成一个新目录，后续合并。按索引粒度，生成索引、`.mrk` 和 `.bin`。数据查询，借助分区、索引缩写数据范围，用标记文件确定要解压的文件。若过滤条件未匹配到索引，要扫描所有目录，用数据标记多线程读取压缩块提升性能。

`TTL` 可设置列级别和表级别。可以修改但不可取消。设置 `TTL` 后每个分区目录生成一个 `ttl.txt` 文件，用 `json` 保留相关信息，合并分区时触发删除逻辑。有控制全局 `TTL` 任务的启停开关。

一个分区目录可写入多块磁盘。`JBOD` 策略，每生成一个新分区，按磁盘定义顺序，轮询写入各磁盘。`HOT/COLD` 策略，设置阈值，超过阈值的分区写入 `COLD` 卷，其他情况写入 `HOT`。

`ReplacingMergeTree`，按排序键去重，合并分区才触发去重，只能以数据分区为单位去重，若设置版本号，取版本号取值最大的一行，否则保留同一组重复数据最后一行。

`SummingMergeTree`，合并分区时按排序键聚合数据。默认主键和排序键相同，若同时声明强制要求主键必须是排序键的前缀，保证不出现索引和数据顺序混乱的情况。

`AggregatingMergeTree`，将要聚合的数据预计算，保存结果，查询时使用结果数据。常作为物化视图的表引擎，物化视图是其他表上层的查询视图。分区合并才触发聚合，以分区为单位聚合，用 `AggregateFunction ` 定义聚合函数类型。

`CollapsingMergeTree`，支持行级数据修改删除，以增代删。定义 `sign` 标记位记录行状态，分区合并时将1和-1的行抵消。分区为单位，分区合并时才合并，以排序键作为合并依据。

`VersionedCollapsingMergeTree`，对数据写入顺序无要求，除了定义 `sign` 标记，还需要指定 `ver` 版本号加入排序键。

`ReplicatedMergeTree`，增加了分布式协同能力，借助 `Zookeeper` 实现副本间的数据同步。

外部存储表引擎，从其他存储系统读数据。`Kafka` 表，一整个数据块写入数据表才提交偏移量。默认500毫秒拉一次数据，先放入缓存，之后刷新到数据表。一个数据块完成写入或间隔超过配置会触发刷新。`Kafka` 表执行查询后会删除表内数据，只充当数据管道，需要有另一个表引擎充当面向用户的查询表，由一张物化视图将 `Kafka` 表数据同步到查询表。

`Memory` 表引擎，将数据保存在内存，数据不被压缩也不被转换。

数据量过大，用 `Sharding` 方案，将一个数据表实例横向扩展到多个数据库实例。一个数据库实例是一个 `Shard` 分片，数据写入要均匀写入各个 `Shard`，查询时从每个 `Shard` 查询归并结果。`Distributed` 引擎不存数据，只做代理。

集群不要求所有节点组成，可划分成多个小集群，各个小集群的分区副本数可不相同。分片之间的数据是不同的，副本之间的数据是相同的。副本是实现冗余防止数据丢失，分片是实现水平切分。一个数据分区从开始创建到全部完成，先写入内存缓冲区，接着被写入 `tmp` 临时目录分区，全部完成后重命名为正式分区。`ReplicatedMergeTree` 在 `Zookeeper` 创建临时节点，实现多实例通信，实现插入和修改时实现多副本同步。副本是表级别的。多主架构，可在任意副本执行修改。执行插入将数据分成数据块，是数据写入的基本单元，保证写入的原子性。

有一张系统表可查 `Zookeeper` 路径信息。创建副本表要指定 `zk_path` 和副本名，副本名可以是 `host`。

副本表创建过程，以 `zk_path` 为根路径，创建一组监听节点。元数据节点：主键、分区键、列信息、副本名。判断标识：主副本选举，合并和修改操作在主副本完成后将消息发给其他副本。`Block` 的哈希信息及分区，判断是否重复。`Block` 写入顺序。写入成功的副本数。操作日志：副本需要执行的指令，用持久顺序节点，所有副本监听 `/log`，有新指令加入，加入到各自的任务队列。每个副本单独的节点：最后执行的日志指针，执行的任务。

有副本执行操作加入 `/log`，其他副本监听到加入自己的任务队列。`merge` 操作无论在哪个副本上触发，都被转移到主副本。

分片需要结合分布式表，分布式表本身不存储数据只做代理。分布式建表，先执行的节点监控集群进度，建表日志推送到 `Zookeeper`。监控到事件的节点拉取日志到本地，若判断需要执行，进入流程，执行完状态写入 `finished` 节点。

一张本地表对应一个分片，以 `_local` 命名，分布式表以 `_all` 命名，与本地表形成一对多的映射关系。分布式表引擎读时检查，若表结构不兼容，查询时会抛错，创建表时不检查。

分布式表对写入和查询过程，用集群配置找到相应的节点，用数据库和表映射到本地表，根据分片键规则，将数据分布到各个本地表。集群模式建一张分布式表，可对任意节点发送请求代理。

对分布式表的查询，`INSERT` 和 `SELECT` 会作用于本地表。`CREATE`、`DROP`、`RENAME` 只作用于分布式表。若要彻底删除，还需要再删除本地表。分布式表不支持删除和更新操作。分片键需要返回一个整数，声明后才能包含多个分片。分片权重会影响数据在分片中的倾斜程度。`slot` 计算用分片键取余所有分片的权重总和，根据 `slot` 找到对应的数据分片。

写入数据，一种是外部系统对数据分桶，直接写入对应的本地表。另一种是分布式表引擎代理写入分片数据。

谁执行谁负责，接受请求的分布式表切分数据发给其他节点。若设置副本，一种方法由分布式表分发副本数据，同时负责分片和副本的写入，但容易成为单点瓶颈。另一种方法用 `ReplicatedMergeTree` 作为本地表引擎，副本的复制由本地表自己处理。

集群查询数据，只能通过分布式表引擎。若一个分片有多副本，用负载均衡算法选择一个。按分片数量拆成多个子查询，分别发起查询，最后汇总各个结果。
